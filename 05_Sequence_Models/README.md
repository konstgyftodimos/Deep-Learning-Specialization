# NLP Sequence Models
[https://www.coursera.org/learn/nlp-sequence-models]

## Objectives:
- Learn about recurrent neural networks. This type of model has been proven to perform extremely well on temporal data. It has several variants including LSTMs, GRUs and Bidirectional RNNs.
- Natural Language Processing & Word Embeddings. Examples of applications are sentiment analysis, named entity recognition and machine translation.
- Sequence models & Attention mechanism.
  
## Week 1:
-   Building a Recurrent Neural Network - Step by Step
-   Dinosaurus Island -- Character level language model final
-   Improvise a Jazz Solo with an LSTM Network
  
## Week 2:
-   Operations on word vectors 
-   Emojify
  
## Week 3:
-   Neural machine translation with attention
-   Trigger word detection
  
